{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "R2QIqqInT1E5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import ImageFilter\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.utils import resample\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Se elije una carpeta desde donde se trabaja\n",
        "mainpathlocation = 'D:/CosasUniversidad/Material/ULA6-Semestre12/Taller-de-Titulo-II/Recursos/HAM10000/HAMTESTS/'\n",
        "#mainpathlocation = 'C:/Users/malz1/Desktop/2023/tesis/'\n",
        "os.chdir(mainpathlocation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n"
          ]
        }
      ],
      "source": [
        "#Se lee el csv y se obtienen las clases\n",
        "metadf = pd.read_csv(mainpathlocation+\"HAM10000_metadata.csv\")\n",
        "le = LabelEncoder()\n",
        "le.fit(metadf['dx'])\n",
        "LabelEncoder()\n",
        "print(list(le.classes_))\n",
        "\n",
        "metadf['label'] = le.transform(metadf[\"dx\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se \"enlazan\" los datos en el csv con sus imagenes correspondientes\n",
        "os.chdir(mainpathlocation)\n",
        "image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
        "              for x in glob(os.path.join('FullHAM/','*.jpg'))}\n",
        "metadf['path'] = metadf['image_id'].map(image_path.get)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resample (data balancing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "5    6705\n",
            "4    1113\n",
            "2    1099\n",
            "1     514\n",
            "0     327\n",
            "6     142\n",
            "3     115\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "0    500\n",
            "1    500\n",
            "2    500\n",
            "3    500\n",
            "4    500\n",
            "5    500\n",
            "6    500\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import resample\n",
        "print(metadf['label'].value_counts())\n",
        "\n",
        "metadf_0 = metadf[metadf['label'] == 0]\n",
        "metadf_1 = metadf[metadf['label'] == 1]\n",
        "metadf_2 = metadf[metadf['label'] == 2]\n",
        "metadf_3 = metadf[metadf['label'] == 3]\n",
        "metadf_4 = metadf[metadf['label'] == 4]\n",
        "metadf_5 = metadf[metadf['label'] == 5]\n",
        "metadf_6 = metadf[metadf['label'] == 6]\n",
        "\n",
        "#Se equilibran los datos, para evitar un sobreajuste en el entrenamiento\n",
        "#Se elije la cantidad de datos en cada clase modificando n_samples\n",
        "n_samples=1500\n",
        "metadf_0_balanced = resample(metadf_0, replace=True, n_samples=n_samples, random_state=42) \n",
        "metadf_1_balanced = resample(metadf_1, replace=True, n_samples=n_samples, random_state=42) \n",
        "metadf_2_balanced = resample(metadf_2, replace=True, n_samples=n_samples, random_state=42)\n",
        "metadf_3_balanced = resample(metadf_3, replace=True, n_samples=n_samples, random_state=42)\n",
        "metadf_4_balanced = resample(metadf_4, replace=True, n_samples=n_samples, random_state=42)\n",
        "metadf_5_balanced = resample(metadf_5, replace=True, n_samples=n_samples, random_state=42)\n",
        "metadf_6_balanced = resample(metadf_6, replace=True, n_samples=n_samples, random_state=42)\n",
        "\n",
        "metadf = pd.concat([metadf_0_balanced, metadf_1_balanced, \n",
        "                              metadf_2_balanced, metadf_3_balanced, \n",
        "                              metadf_4_balanced, metadf_5_balanced, metadf_6_balanced])\n",
        "\n",
        "#Balanced classes\n",
        "print(metadf['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cropping machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se define una función que corta las imagenes centrando la imagen en el centro de la lesion\n",
        "def cropImageFromCenter(centerX,centerY,ogWidth,ogHeight,ratio):\n",
        "    croppedWidth = ogWidth*ratio\n",
        "    croppedHeight = ogHeight*ratio\n",
        "\n",
        "    if centerX - croppedWidth/2 < 0:\n",
        "      croppedA = 0\n",
        "      croppedB = centerX + croppedWidth/2 + (croppedWidth/2-centerX)\n",
        "    elif centerX + croppedWidth/2 > ogWidth:\n",
        "      croppedA = centerX - croppedWidth/2 - ((croppedWidth/2+centerX)-ogWidth)\n",
        "      croppedB = ogWidth\n",
        "    else:\n",
        "      croppedA = centerX - croppedWidth/2\n",
        "      croppedB = centerX + croppedWidth/2\n",
        "\n",
        "    if centerY-croppedHeight/2 < 0:\n",
        "      croppedC = 0\n",
        "      croppedD = centerY + croppedHeight/2 + (croppedHeight/2-centerY)\n",
        "    elif centerY+croppedHeight/2 > ogHeight:\n",
        "      croppedC = centerY - croppedHeight/2 - ((croppedHeight/2+centerY)-ogHeight)\n",
        "      croppedD = ogHeight\n",
        "    else:\n",
        "      croppedC = centerY - croppedHeight/2\n",
        "      croppedD = centerY + croppedHeight/2\n",
        "\n",
        "    return croppedA,croppedB,croppedC,croppedD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Métodos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Funcion que elimina los pelos de la imagen\n",
        "def dullRazor(path): \n",
        "    image=cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "    grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY )\n",
        "    kernel = cv2.getStructuringElement(1,(9,9))\n",
        "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
        "    bhg = cv2.GaussianBlur(blackhat,(3,3),cv2.BORDER_DEFAULT)\n",
        "    ret,mask = cv2.threshold(bhg,10,255,cv2.THRESH_BINARY)\n",
        "    dst = cv2.inpaint(image,mask,6,cv2.INPAINT_TELEA)\n",
        "    return dst\n",
        "#devuelve a color\n",
        "\n",
        "#Se elimina el ruido\n",
        "def medianFilter(image):\n",
        "    img = cv2.medianBlur(image, 3)\n",
        "    return img\n",
        "\n",
        "#Segmenta la imagen en blanco y negro\n",
        "def segment(image):\n",
        "    img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    ret, thresh1 = cv2.threshold(img, 125, 255, cv2.THRESH_BINARY_INV)\n",
        "    return thresh1\n",
        "\n",
        "#encuentra el centro de la herida y corta usando la funcion de corte definida anteriormente\n",
        "def center_crop(image):\n",
        "    h,w = image.shape\n",
        "    imageMoments = cv2.moments(image)\n",
        "    if imageMoments['m00'] == 0:\n",
        "        cx = w/2\n",
        "        cy = h/2\n",
        "    else:\n",
        "        cx = int(imageMoments['m10']/imageMoments['m00'])\n",
        "        cy = int(imageMoments['m01']/imageMoments['m00'])\n",
        "    croppedA,croppedB,croppedC,croppedD = cropImageFromCenter(cx,cy,w,h,0.9)\n",
        "    image = image[int(croppedC):int(croppedD), int(croppedA):int(croppedB)]\n",
        "    return image\n",
        "    \n",
        "def preProcess(x):\n",
        "    x = dullRazor(x)\n",
        "    x = medianFilter(x)\n",
        "    x = segment(x)\n",
        "    x = center_crop(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#A continuación se separan las funciones de entrenamiento por tipo de dato\n",
        "#Así, se puede entrenar con solo lo que se requiera, y se guarda en un archivo .pkl para uso en svmTraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Asimetria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def getAsimetria(image):\n",
        "    h, w = image.shape\n",
        "    if h > w:\n",
        "        image = image[int((h-w)/2):int(h-((h-w)/2)), int(0): int(w)]\n",
        "    elif w > h:\n",
        "        image = image[int(0):int(h), int((w-h)/2): int(w-((w-h)/2))]    \n",
        "    else:\n",
        "        image\n",
        "    X_Hist = cv2.calcHist(image, [0], None, [256], [0,256], False)\n",
        "    Y_Hist = cv2.calcHist(image, [157], None, [256], [0,256], False)\n",
        "    compare_val = cv2.compareHist(X_Hist ,Y_Hist,cv2.HISTCMP_INTERSECT)\n",
        "    #print(compare_val)\n",
        "    return compare_val\n",
        "metadf['Asimetria'] = metadf['path'].map(lambda x: np.asarray( getAsimetria(preProcess(x))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf.to_pickle(\"svmDataset.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Circularidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "#os.chdir(mainpathlocation)\n",
        "#DEBE RECIBIR GRAYSCALE\n",
        "def getCircularidad(image):\n",
        "    imageMoments = cv2.moments(image)\n",
        "    area = imageMoments['m00']\n",
        "    contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    perimeter = 0\n",
        "    for coords in contours:\n",
        "      perimeter = perimeter + cv2.arcLength(coords, False)\n",
        "    if perimeter == 0:\n",
        "      perimeter = 1\n",
        "    circularity = (4*area*math.pi)/perimeter*perimeter\n",
        "    return circularity\n",
        "    \n",
        "\n",
        "metadf['Circularidad'] = metadf['path'].map(lambda x: np.asarray( getCircularidad(preProcess(x)) ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf.to_pickle(\"svmDataset.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getThinRatio(img):\n",
        "    imageMoments = cv2.moments(img)\n",
        "    area = imageMoments['m00']\n",
        "    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    perimeter = 0\n",
        "    for coords in contours:\n",
        "      perimeter = perimeter + cv2.arcLength(coords, False)\n",
        "    if perimeter == 0:\n",
        "      perimeter = 1\n",
        "    return 4*math.pi*(area/(perimeter*perimeter))\n",
        "\n",
        "metadf['ThinRatio'] = metadf['path'].map(lambda x: np.asarray( getThinRatio(preProcess(x)) ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf.to_pickle(\"svmDataset.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getAspectRatio(img):\n",
        "    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    xA=[] \n",
        "    yA=[] \n",
        "    w=0\n",
        "    h=0\n",
        "    for coords in contours:\n",
        "        x2,y2,w2,h2 = cv2.boundingRect(coords)\n",
        "        xA.append(x2)\n",
        "        yA.append(y2)\n",
        "    \n",
        "    if (len(xA) != 0) and (len(yA) != 0):\n",
        "        x = xA[np.argmin(xA)]\n",
        "        y = yA[np.argmin(yA)]\n",
        "        w = xA[np.argmax(xA)] - x\n",
        "        h = yA[np.argmax(yA)] - y\n",
        "    if h == 0:\n",
        "        h = 1\n",
        "    return (w/h)\n",
        "\n",
        "metadf['AspectRatio'] = metadf['path'].map(lambda x: np.asarray( getAspectRatio(preProcess(x)) ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf['AvgRed'] = metadf['path'].map(lambda x: np.asarray( np.mean(medianFilter(dullRazor(x))[:,:,0])) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf['AvgGreen'] = metadf['path'].map(lambda x: np.asarray( np.mean(medianFilter(dullRazor(x))[:,:,1])) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf['AvgBlue'] = metadf['path'].map(lambda x: np.asarray( np.mean(medianFilter(dullRazor(x))[:,:,2])) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf.to_pickle(\"svmDataset.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf['AvgHue'] = metadf['path'].map(lambda x: np.asarray( np.mean(cv2.cvtColor(medianFilter(dullRazor(x)), cv2.COLOR_RGB2HSV)[:,:,0]) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf['AvgSaturation'] = metadf['path'].map(lambda x: np.asarray( np.mean(cv2.cvtColor(medianFilter(dullRazor(x)), cv2.COLOR_RGB2HSV)[:,:,1]) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf.to_pickle(\"svmDataset.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getDiameter(img):\n",
        "    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    xA=[] \n",
        "    yA=[] \n",
        "    w=0\n",
        "    h=0\n",
        "    for coords in contours:\n",
        "        x2,y2,w2,h2 = cv2.boundingRect(coords)\n",
        "        xA.append(x2)\n",
        "        yA.append(y2)\n",
        "    \n",
        "    if (len(xA) != 0) and (len(yA) != 0):\n",
        "        x = xA[np.argmin(xA)]\n",
        "        y = yA[np.argmin(yA)]\n",
        "        w = xA[np.argmax(xA)] - x\n",
        "        h = yA[np.argmax(yA)] - y\n",
        "    diametro = 0\n",
        "    if w>h:\n",
        "      diametro = w\n",
        "    else:\n",
        "      diametro = h\n",
        "    return diametro\n",
        "\n",
        "metadf['Diameter'] = metadf['path'].map(lambda x: np.asarray( getDiameter(preProcess(x)) ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getIntensityAverage(x):\n",
        "    \n",
        "    avgR = np.mean(x[:,0])\n",
        "    avgG = np.mean(x[:,1])\n",
        "    avgB = np.mean(x[:,2])\n",
        "    return (avgR+avgG+avgB)/3\n",
        "\n",
        "\n",
        "metadf['AvgIntensity'] = metadf['path'].map(lambda x: np.asarray( getIntensityAverage(medianFilter(dullRazor(x))[:,:,0])) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadf.to_pickle(\"svmDataset.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
